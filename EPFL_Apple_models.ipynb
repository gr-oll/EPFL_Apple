{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe38780",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cfdb375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf01c24",
   "metadata": {},
   "source": [
    "# Collaborative Filtering (first attempts)\n",
    "Recommendations based on user-item interactions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ccc79d",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02c7b3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 73892\n",
      "Testing set size: 13155\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "interactions = pd.read_csv('kaggle_data/interactions_train.csv')\n",
    "items = pd.read_csv('kaggle_data/items.csv')\n",
    "\n",
    "interactions = interactions.sort_values([\"u\", \"t\"])\n",
    "\n",
    "interactions[\"pct_rank\"] = interactions.groupby(\"u\")[\"t\"].rank(pct=True, method='dense')\n",
    "interactions.reset_index(inplace=True, drop=True)\n",
    "\n",
    "train_data = interactions[interactions[\"pct_rank\"] < 0.9]\n",
    "test_data = interactions[interactions[\"pct_rank\"] >= 0.9]\n",
    "\n",
    "\n",
    "print(\"Training set size:\", train_data.shape[0])\n",
    "print(\"Testing set size:\", test_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a002c08",
   "metadata": {},
   "source": [
    "### Collaborative Filtering (simple approach)\n",
    "Using the initial raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7ebe577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>i</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15279</th>\n",
       "      <th>15280</th>\n",
       "      <th>15282</th>\n",
       "      <th>15283</th>\n",
       "      <th>15284</th>\n",
       "      <th>15285</th>\n",
       "      <th>15287</th>\n",
       "      <th>15288</th>\n",
       "      <th>15289</th>\n",
       "      <th>15290</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7838 rows × 14853 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "i     0      1      2      3      4      5      6      7      8      9      \\\n",
       "u                                                                            \n",
       "0         1      1      1      1      1      1      1      1      1      1   \n",
       "1         0      0      0      0      0      0      0      0      0      0   \n",
       "2         0      0      0      0      0      0      0      0      0      0   \n",
       "3         0      0      0      0      0      0      0      0      0      0   \n",
       "4         0      0      0      0      0      0      0      0      0      0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "7833      0      0      0      0      0      0      0      0      0      0   \n",
       "7834      0      0      0      0      0      0      0      0      0      0   \n",
       "7835      0      0      0      0      0      0      0      0      0      0   \n",
       "7836      0      0      0      0      0      0      0      0      0      0   \n",
       "7837      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "i     ...  15279  15280  15282  15283  15284  15285  15287  15288  15289  \\\n",
       "u     ...                                                                  \n",
       "0     ...      0      0      0      0      0      0      0      0      0   \n",
       "1     ...      0      0      0      0      0      0      0      0      0   \n",
       "2     ...      0      0      0      0      0      0      0      0      0   \n",
       "3     ...      0      0      0      0      0      0      0      0      0   \n",
       "4     ...      0      0      0      0      0      0      0      0      0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "7833  ...      0      0      0      0      0      0      0      0      0   \n",
       "7834  ...      0      0      0      0      0      0      0      0      0   \n",
       "7835  ...      0      0      0      0      0      0      0      0      0   \n",
       "7836  ...      0      0      0      0      0      0      0      0      0   \n",
       "7837  ...      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "i     15290  \n",
       "u            \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "7833      0  \n",
       "7834      0  \n",
       "7835      0  \n",
       "7836      0  \n",
       "7837      0  \n",
       "\n",
       "[7838 rows x 14853 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a user-item interaction matrix with binary values (1 if read, 0 otherwise)\n",
    "binary_interaction_matrix = train_data.pivot_table(index='u', columns='i', values='t', aggfunc='count')\n",
    "binary_interaction_matrix = binary_interaction_matrix.notnull().astype(int)\n",
    "\n",
    "binary_interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38115b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>u</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7828</th>\n",
       "      <th>7829</th>\n",
       "      <th>7830</th>\n",
       "      <th>7831</th>\n",
       "      <th>7832</th>\n",
       "      <th>7833</th>\n",
       "      <th>7834</th>\n",
       "      <th>7835</th>\n",
       "      <th>7836</th>\n",
       "      <th>7837</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7838 rows × 7838 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "u     0     1         2     3     4     5     6     7     8     9     ...  \\\n",
       "u                                                                     ...   \n",
       "0      1.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1      0.0   1.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2      0.0   0.0  1.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3      0.0   0.0  0.000000   1.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4      0.0   0.0  0.000000   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "...    ...   ...       ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "7833   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "7834   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "7835   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "7836   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "7837   0.0   0.0  0.101015   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "u     7828  7829  7830  7831  7832  7833  7834  7835  7836      7837  \n",
       "u                                                                     \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.101015  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...       ...  \n",
       "7833   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0  0.000000  \n",
       "7834   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  0.000000  \n",
       "7835   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  0.000000  \n",
       "7836   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  0.000000  \n",
       "7837   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  1.000000  \n",
       "\n",
       "[7838 rows x 7838 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Cosine Similarity Between Users\n",
    "user_similarity = cosine_similarity(binary_interaction_matrix)\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=binary_interaction_matrix.index, columns=binary_interaction_matrix.index)\n",
    "user_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1bec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8    9\n",
      "u                                                  \n",
      "0   13    4   12   15    8   11   14   10    5   17\n",
      "1   38   34   31   30   37   29   32   33   36   35\n",
      "2   46   58   53   49   56   64   91   82   71   45\n",
      "3  149  163  128  143  133  138   40  155  142  156\n",
      "4  202  203  198  191  193  201  195  197  205  196\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "# User-item scores for every user in one shot\n",
    "scores = user_similarity_df.values @ binary_interaction_matrix.values        # (U, I)\n",
    "\n",
    "# Indices of each user’s k best-scoring items (unsorted)\n",
    "top_idx_unsorted = np.argpartition(-scores, k-1, axis=1)[:, :k]              # (U, k)\n",
    "\n",
    "# Sort those k items per user so they’re really rank-ordered\n",
    "rows   = np.arange(scores.shape[0])[:, None]                                  # (U, 1)\n",
    "order  = np.argsort(-scores[rows, top_idx_unsorted], axis=1)\n",
    "top_idx = top_idx_unsorted[rows, order]                                       # (U, k) sorted\n",
    "\n",
    "# Look up the *labels* with NumPy → 2-D array → DataFrame\n",
    "item_labels = binary_interaction_matrix.columns.to_numpy()                    # (I,)\n",
    "top_labels  = item_labels[top_idx]                                            # (U, k)\n",
    "\n",
    "recommendations = pd.DataFrame(\n",
    "    top_labels,                      \n",
    "    index=binary_interaction_matrix.index, \n",
    "    columns=range(k)                        \n",
    ")\n",
    "\n",
    "# quick peek\n",
    "print(recommendations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9823a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each row of recommendations to a space-separated string\n",
    "recommendations_str = recommendations.apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
    "\n",
    "# Export to CSV with a single-column header\n",
    "recommendations_str.to_csv('recommendations.csv', index=True, header=['recommendation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb401ccd",
   "metadata": {},
   "source": [
    "### Collaborative Filtering (better predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1682b586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\n",
       "0    [611, 46, 4, 8999, 794, 3407, 3811, 685, 13, 2...\n",
       "1    [611, 789, 4220, 5140, 2959, 769, 796, 176, 33...\n",
       "2    [46, 323, 56, 2130, 5748, 3055, 66, 8999, 70, 64]\n",
       "3    [163, 149, 618, 611, 128, 466, 119, 4, 2614, 143]\n",
       "4    [424, 323, 201, 2225, 428, 423, 976, 422, 324,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply TruncatedSVD to reduce dimensionality\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "user_factors = svd.fit_transform(binary_interaction_matrix.values)\n",
    "item_factors = svd.components_\n",
    "\n",
    "# Reconstruct approximate interaction scores\n",
    "approx_scores = user_factors @ item_factors\n",
    "\n",
    "# Convert reconstructed scores into a DataFrame (same indexes and columns as original)\n",
    "approx_scores_df = pd.DataFrame(approx_scores, index=binary_interaction_matrix.index, columns=binary_interaction_matrix.columns)\n",
    "\n",
    "# Get top 10 items for each user\n",
    "k = 10\n",
    "recommendations_svd = approx_scores_df.apply(lambda row: row.nlargest(k).index.tolist(), axis=1)\n",
    "recommendations_svd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f011c",
   "metadata": {},
   "source": [
    "# Collaborative Filtering (the best scores)\n",
    "Recommendations based on user-item interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093bf7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable or disable the upscaling of individual book weights for users with low book counts\n",
    "upscale_low_book = True\n",
    "\n",
    "# Define the threshold for the number of books below which upscaling will be applied\n",
    "threshold_low_book = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c94883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "interactions = pd.read_csv('kaggle_data/interactions_train.csv')\n",
    "items = pd.read_csv('kaggle_data/items.csv')\n",
    "\n",
    "# Aggregate interactions to calculate the number of unique items each user has interacted with\n",
    "interactions_agg = interactions.groupby('u').agg(\n",
    "    {\n",
    "        'i': pd.Series.nunique,\n",
    "    }\n",
    ").reset_index().rename(\n",
    "    columns={\n",
    "        'i': 'n_items'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Check the loaded data\n",
    "# Ensure the interactions dataset contains the required columns and is not empty\n",
    "assert 'u' in interactions.columns and 'i' in interactions.columns and 't' in interactions.columns, \"Interactions file missing required columns\"\n",
    "assert not interactions.empty, \"Interactions dataset is empty\"\n",
    "\n",
    "# Ensure the items dataset contains the required columns and is not empty\n",
    "assert 'Title' in items.columns and 'i' in items.columns, \"Items file missing required columns\"\n",
    "assert not items.empty, \"Items dataset is empty\"\n",
    "\n",
    "# Following adjustments\n",
    "interactions = interactions.sort_values([\"u\", \"t\"], ascending=[True, False])\n",
    "\n",
    "# Calculate the percentile rank of each interaction within a user's interactions\n",
    "interactions[\"pct_rank\"] = interactions.groupby(\"u\")[\"t\"].rank(pct=True, method='dense')\n",
    "interactions.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Merge the interactions dataset with the aggregated data to include the number of unique items per user\n",
    "interactions = interactions.merge(interactions_agg, on='u', how='left')\n",
    "interactions['weight'] = interactions[\"pct_rank\"]\n",
    "\n",
    "# If the upscale_low_book flag is True, assign a weight of 1 to interactions for users with a number of unique items less than or equal to the threshold\n",
    "if upscale_low_book:\n",
    "    interactions.loc[interactions['n_items'] <= threshold_low_book, 'weight'] = 1\n",
    "\n",
    "inter_data = interactions.copy()\n",
    "\n",
    "# Create binary interaction matrix\n",
    "binary_interaction_matrix = inter_data.pivot_table(index='u', columns='i', values='weight', aggfunc='sum')\n",
    "binary_interaction_matrix = binary_interaction_matrix.fillna(0)  # Fill NaN with 0\n",
    "\n",
    "# Compute cosine similarity and test symmetry\n",
    "user_similarity = cosine_similarity(binary_interaction_matrix)\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=binary_interaction_matrix.index, columns=binary_interaction_matrix.index)\n",
    "\n",
    "assert np.allclose(user_similarity_df, user_similarity_df.T), \"User similarity matrix is not symmetric\"\n",
    "\n",
    "# Top-10 Recommendations from this approach\n",
    "k = 10\n",
    "scores = user_similarity_df.values @ binary_interaction_matrix.values\n",
    "top_idx_unsorted = np.argpartition(-scores, k-1, axis=1)[:, :k]              \n",
    "rows = np.arange(scores.shape[0])[:, None]\n",
    "order = np.argsort(-scores[rows, top_idx_unsorted], axis=1)\n",
    "top_idx = top_idx_unsorted[rows, order]\n",
    "item_labels = binary_interaction_matrix.columns.to_numpy()                    \n",
    "top_labels = item_labels[top_idx]                                            \n",
    "recommendations = pd.DataFrame(top_labels, index=binary_interaction_matrix.index, columns=range(k))\n",
    "assert recommendations.shape[0] == binary_interaction_matrix.shape[0], \"Number of recommendation rows differs from number of users\"\n",
    "assert recommendations.shape[1] == k, \"Each user should have 10 recommendations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each row of recommendations to a space-separated string\n",
    "recommendations_str = recommendations.apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
    "\n",
    "# Export recommendations to a CSV file\n",
    "if upscale_low_book:\n",
    "    recommendations_str.to_csv(\n",
    "        f'recommendations_collab_weight_pct_upscale_1_nitems_{threshold_low_book}.csv',\n",
    "        index=True,\n",
    "        header=['recommendation'],\n",
    "        index_label='user_id'\n",
    "    )\n",
    "else:\n",
    "    recommendations_str.to_csv(\n",
    "        'recommendations_collab_weight_pct.csv',\n",
    "        index=True,\n",
    "        header=['recommendation'],\n",
    "        index_label='user_id'\n",
    "    )\n",
    "\n",
    "# recommendations_collab_weight_pct_upscale_1_nitems_2.csv = 0.1642 (the best score)\n",
    "# recommendations_collab_weight_pct.csv = 0.1637 (the second best score): without upscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9e987e",
   "metadata": {},
   "source": [
    "# TFIDF-Based Book Recommendations (not cleaned dataset)\n",
    "This section demonstrates how to generate book recommendations for each user based on the similarity of books they have already read using the TFIDF approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b201ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer using French stop words and fit-transform the 'combined_features' column of the books\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=french_stop_words)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(books['combined_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive_limit_bool = True, if you want to limit the recommendations, otherwise set it to False\n",
    "naive_limit_bool = True\n",
    "\n",
    "interactions_agg = interactions.groupby('u').agg(\n",
    "    min_book_id = ('i', min),\n",
    "    max_book_id = ('i', max),\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# Compute recommendations for each user\n",
    "user_recommendations = {}\n",
    "for user_id, group in interactions.groupby('u'):\n",
    "    read_books = group['i'].values\n",
    "    read_books_indices = [books[books['i'] == book_id].index[0] for book_id in read_books]\n",
    "    read_books_tfidf = tfidf_matrix[read_books_indices]\n",
    "    similarity_scores = cosine_similarity(read_books_tfidf, tfidf_matrix)\n",
    "    avg_similarity = np.mean(similarity_scores, axis=0)\n",
    "    recommended_indices = avg_similarity.argsort()[-15288:][::-1]\n",
    "\n",
    "    recommended_books = books.iloc[recommended_indices]['i'].values\n",
    "\n",
    "    if naive_limit_bool:\n",
    "        lower_bound = interactions_agg[interactions_agg['u'] == user_id]['min_book_id'].values[0]\n",
    "        upper_bound = interactions_agg[interactions_agg['u'] == user_id]['max_book_id'].values[0]\n",
    "        \n",
    "        if upper_bound > lower_bound:\n",
    "            upper_bound = min(upper_bound+11, 15290)\n",
    "            recommended_books = recommended_books[(recommended_books >= lower_bound) & (recommended_books <= upper_bound)]\n",
    "\n",
    "        if len(recommended_books) < 10:\n",
    "            print(f\"User {user_id} has less than 10 recommendations. Found: {len(recommended_books)}\")\n",
    "            print(\"upper_bound:\", upper_bound)\n",
    "            print(\"lower_bound:\", lower_bound)\n",
    "    \n",
    "    user_recommendations[user_id] = recommended_books[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0491e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display recommendations for a sample user\n",
    "sample_user_id = list(user_recommendations.keys())[0]\n",
    "print(f\"Recommendations for User {sample_user_id}:\")\n",
    "print(user_recommendations[sample_user_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d747103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export recommendations to a CSV file\n",
    "with open('recommendations_tfidf_naive_proper_input_less_features.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['user_id', 'recommendation'])\n",
    "    for user_id, recommended_books in user_recommendations.items():\n",
    "        writer.writerow([user_id, \" \".join(map(str, recommended_books))])\n",
    "\n",
    "# Score = 0.1560\n",
    "print(\"Recommendations exported to recommendations_tfidf_naive_proper_input_less_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5450ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each user, who has read only one unique book (does not matter once or several times), recommend 10 times the same book\n",
    "user_embeddings_df = interactions.copy()\n",
    "\n",
    "user_embeddings_df = user_embeddings_df.sort_values(by=[\"u\", \"t\"],ascending=[True, False]).reset_index(drop=True)\n",
    "user_embeddings_df['last_unique_books'] = user_embeddings_df\\\n",
    "        .groupby('u')['i']\\\n",
    "        .apply(lambda x: (~pd.Series(x).duplicated()).cumsum()).reset_index(drop=True)\n",
    "\n",
    "# Get users who have read exactly 1 unique book\n",
    "users_with_1_unique_book = user_embeddings_df.groupby('u')['i'].nunique()\n",
    "users_with_1_unique_book = users_with_1_unique_book[users_with_1_unique_book == 1].index\n",
    "u_1 = user_embeddings_df[user_embeddings_df['u'].isin(users_with_1_unique_book)].drop_duplicates(subset=['u', 'i'])\n",
    "u_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9311701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id in u_1['u'].unique():\n",
    "    book_id = u_1[u_1['u'] == user_id]['i'].values[0]\n",
    "    # Create a recommendation list with 10 copies of the book ID\n",
    "    user_recommendations[user_id] = [book_id] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2807d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export recommendations to a CSV file\n",
    "with open('recommendations_tfidf_naive_proper_input_less_features_1.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['user_id', 'recommendation'])\n",
    "    for user_id, recommended_books in user_recommendations.items():\n",
    "        writer.writerow([user_id, \" \".join(map(str, recommended_books))])\n",
    "\n",
    "# Score = 0.1558\n",
    "print(\"Recommendations exported to recommendations_tfidf_naive_proper_input_less_features_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d952a24f",
   "metadata": {},
   "source": [
    "# TFIDF-Based Book Recommendations (cleaned dataset)\n",
    "This section demonstrates how to generate book recommendations for each user based on the similarity of books they have already read using the TFIDF approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf7ca18",
   "metadata": {},
   "source": [
    "### Cleaning the data (same as in the EPFL_Apple_EDA file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ba60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ushakov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/var/folders/m9/3cstgvvd2ds4y_qkq_p0lnrh0000gn/T/ipykernel_34770/4251609911.py:159: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_relevant_cols[\"prep_author\"] = df_relevant_cols[['authors', 'Author']].fillna(method='bfill', axis=1).iloc[:, 0]\\\n",
      "/var/folders/m9/3cstgvvd2ds4y_qkq_p0lnrh0000gn/T/ipykernel_34770/4251609911.py:159: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_relevant_cols[\"prep_author\"] = df_relevant_cols[['authors', 'Author']].fillna(method='bfill', axis=1).iloc[:, 0]\\\n",
      "/var/folders/m9/3cstgvvd2ds4y_qkq_p0lnrh0000gn/T/ipykernel_34770/4251609911.py:182: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_relevant_cols[\"prep_publisher\"]  = df_relevant_cols[['publisher','Publisher']].fillna(method='bfill', axis=1).iloc[:, 0]\\\n",
      "/var/folders/m9/3cstgvvd2ds4y_qkq_p0lnrh0000gn/T/ipykernel_34770/4251609911.py:186: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_relevant_cols[\"prep_title\"] = df_relevant_cols[['title_long','Title']].fillna(method='bfill', axis=1).iloc[:, 0]\\\n",
      "/var/folders/m9/3cstgvvd2ds4y_qkq_p0lnrh0000gn/T/ipykernel_34770/4251609911.py:193: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_relevant_cols[\"prep_subjects\"] = df_relevant_cols[['subjects','Subjects']].fillna(method='bfill', axis=1).iloc[:, 0]\\\n",
      "/var/folders/m9/3cstgvvd2ds4y_qkq_p0lnrh0000gn/T/ipykernel_34770/4251609911.py:193: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_relevant_cols[\"prep_subjects\"] = df_relevant_cols[['subjects','Subjects']].fillna(method='bfill', axis=1).iloc[:, 0]\\\n"
     ]
    }
   ],
   "source": [
    "# Load book complete data\n",
    "books = pd.read_csv('kaggle_data/books_complete.csv')\n",
    "\n",
    "# Download the NLTK stopwords dataset\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the list of French stop words from the NLTK stopwords corpus\n",
    "french_stop_words = stopwords.words('french')\n",
    "\n",
    "# Function to get the index of the first digit in a given sequence\n",
    "def get_first_digit_index(sequence):\n",
    "    match = re.search(r\"\\d\", str(sequence))\n",
    "    if match:\n",
    "        return match.start()\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "# Function to extract a substring from a given sequence starting from a specified index\n",
    "def substring_from_index(sequence, index):\n",
    "    if index != -1:\n",
    "        # If a valid index is provided, return the substring starting from the index, stripped of leading/trailing spaces\n",
    "        return sequence[:index].strip()\n",
    "    elif type(sequence) == str:\n",
    "        return sequence.strip()\n",
    "    else:\n",
    "        return sequence\n",
    "\n",
    "# Function to remove specific words from a given sequence\n",
    "def remove_words(sequence, list_words):\n",
    "    if type(sequence) == str:\n",
    "        for word in list_words:\n",
    "            sequence = sequence.replace(word, \"\")\n",
    "        return sequence.strip()\n",
    "    else:\n",
    "        return sequence\n",
    "\n",
    "# Function to remove the last comma from a given sequence\n",
    "def remove_last_comma(sequence):\n",
    "    if type(sequence) == str:\n",
    "        return sequence.strip().rstrip(\",\")\n",
    "    else:\n",
    "        return sequence\n",
    "\n",
    "# Drop unnecessary columns from the books dataframe\n",
    "df_relevant_cols = books.drop(\n",
    "    columns=[\"dewey_decimal\", \"image\", \"image_original\", \"dimensions_structured\",\n",
    "             \"msrp\", \"binding\", \"edition\", \"related\", \"dimensions\",]\n",
    ")\n",
    "\n",
    "# Fix 'Author' column\n",
    "stop_words = [\n",
    "        'artiste','actuaire,','avocat,','illustrateur,','juriste,',\n",
    "        'dr. en droit,','dr en droit,','actuaire,','saint','Juge cantonal,','juge cantonal,',\n",
    "        \"auteur d'un ouvrage sur l'art publicitaire\",\n",
    "        \"Docteur ès sciences politiques\",\n",
    "        \"rédactrice en chef d'un magazine sur la nature\",\n",
    "        'archéologue','auteur de BD','dit Benedictus de', 'économiste',\n",
    "        'enseignant','sociologue',  'psychiatre', 'juriste', 'docteur',\n",
    "        \"Historien de l'art\",'photographe','politicien', 'agrégé de lettres',\n",
    "        'historien du canton de Vaud','écrivaine','illustratrice', 'cancérologue',\n",
    "        'journaliste.','romancier','Dr en droit','ca.','dr en droit','pédagogue',\n",
    "        'Dr. en droit','dr en droit. Berne','journaliste de loisirs',\n",
    "        'illustrateur.','historien','historienne','historien de l\\'art',\n",
    "        'Études cinématographiques et Audiovisuelles', 'Morges',\n",
    "        'mathématicien',\n",
    "        \" collaboratrice de recherche à l'université de Lausanne\",\n",
    "        ' Physicien', '\\u200f', '\\u200f \\u200e', ' travailleuse sociale',\n",
    "        ' psychologue', ' journaliste scientifique', ' musicologue',\n",
    "        ' évêque de Césarée', ' auteur culinaire',\n",
    "        ' agrégé de philosophie.', ' aut', ' Esthétique', ' avocat',\n",
    "        ' animatrice et auteure de bande dessinée', ' Dr en histoire',\n",
    "        ' guérisseur', ' médecin', ' rédacteur',\n",
    "        ' professeure à l’Université Côte d’Azur.', ' journaliste',\n",
    "        ' auteur jeunesse', ' comtesse de', '  et professeur',\n",
    "        ' Dr en sc. pol.', ' architecte', ' ne', ' cartographe',\n",
    "        \" professeur d'histoire\", ' Pédagogue', ' ingénieur agronome',\n",
    "        ' e en droit', ' dr en lettres', ' juge cantonal',\n",
    "        ' professeur de littérature française',\n",
    "        \" directeur de la Chambre vaudoise d'agriculture\", ' politologue',\n",
    "        ' latiniste', ' dr en philosophie', \" formateur d'adultes\",\n",
    "        ' égyptologue', ' écrivain', \" l'Ancien\",\n",
    "        ' Dr ès lettres', ' Dr en lettres', ' Dr en histoire de l\\’art',\n",
    "        'animatrice eteure de bande dessinée'\n",
    "]\n",
    "\n",
    "# Remove specific stop words from the 'Author' column\n",
    "df_relevant_cols['Author'] = df_relevant_cols['Author'].apply(remove_words, list_words=stop_words)\n",
    "df_relevant_cols['Author'] = df_relevant_cols['Author'].apply(remove_last_comma)\n",
    "\n",
    "\n",
    "df_relevant_cols['index_first_digit'] = df_relevant_cols['Author'].apply(get_first_digit_index)\n",
    "# Extract the substring from the 'Author' column starting from the first digit index\n",
    "df_relevant_cols['Author'] = df_relevant_cols.apply(\n",
    "    lambda row: substring_from_index(row['Author'], row['index_first_digit']), axis=1\n",
    ")\n",
    "\n",
    "# Remove any trailing commas from the 'Author' column\n",
    "df_relevant_cols['Author'] = df_relevant_cols['Author'].apply(remove_last_comma)\n",
    "df_relevant_cols = df_relevant_cols.drop(columns=['index_first_digit'])\n",
    "\n",
    "# Remove specific phrases or titles from the 'Author' column\n",
    "df_relevant_cols['Author'] = df_relevant_cols['Author'].str.replace(\"gastro-entérologue\",\"\")\\\n",
    "    .str.replace(\"professeur de chimie\",\"\").str.replace(\"-chercheur en histoire de l'art\",\"\")\\\n",
    "    .str.replace(\"professeur de littérature\",\"\").str.replace(\"professeur de littérature française\",\"\")\\\n",
    "    .str.replace(\"professeur de littérature française et de culture générale\",\"\").str.replace(\"professeur de littérature française et de culture générale à l'Université de Lausanne\",\"\")\\\n",
    "    .str.replace(\"professeur d'histoire de l'art\",\"\").str.replace(\"professeur d'histoire de l'art à l'Université de Lausanne\",\"\")\\\n",
    "    .str.replace(\"professeur d'histoire de l'art à l'Université de Lausanne et directeur du Musée cantonal des beaux-arts\",\"\")\\\n",
    "    .str.replace(\"professeur en histoire moderne\",\"\").str.replace(\"blogueur spécialiste des questions climatiques\",\"\")\\\n",
    "    .str.replace(\"chercheur en biologie végétale\",\"\").str.replace(\"ingénieure de formation\",\"\").str.replace(\"en géopolitique\",\"\")\\\n",
    "    .str.replace(\"professeur de lettres modernes\",\"\").str.replace(\"illustrateur et\",\"\").str.replace(\"directrice de recherche CNRS\",\"\")\\\n",
    "    .str.replace(\"e-chercheuse en arabe\",\"\").str.replace(\"experte en intelligence artificielle\",\"\").str.replace(\"en sciences de gestion\",\"\")\\\n",
    "    .str.replace(\"homme politique\",\"\").str.replace(\"expert en stratégie\",\"\").str.replace(\"psychothérapeute\",\"\")\\\n",
    "    .str.replace(\"professeure de yoga\",\"\").str.replace(\"maître de conférence\",\"\").str.replace(\"styliste culinaire\",\"\")\\\n",
    "    .str.replace(\"professeur de didactique du français langue étrangère\",\"\").str.replace(\"anatomiste-\",\"\").str.replace(\"professeur de linguistique française\",\"\")\\\n",
    "    .str.replace(\"e-chercheuse en lettres\",\"\").str.replace(\"en chirurgie dentaire\",\"\").str.replace(\"réalisateur et mangaka\",\"\").str.replace(\"ingénieur forestier et chercheur\",\"\")\\\n",
    "    .str.replace(\"spécialisé dans l'alimentation\",\"\").str.replace(\"en sciences du langage\",\"\").str.replace(\"d'un mémoire de master en histoire\",\"\")\\\n",
    "    .str.replace(\"professeur d'anglais\",\"\").str.replace(\"e en sciences de l'éducation\",\"\").str.replace(\"inspecteur de l'Education Nationale honoraire\",\"\")\\\n",
    "    .str.replace(\"professeur des Universités - Praticien hospitalier en pharmacologie\",\"\").str.replace(\"professeur émérite en Arts plastiques\",\"\").str.replace(\"professeur en Histoire de l'art\",\"\")\\\n",
    "    .str.replace(\"astrophysicienne\",\"\").str.replace(\"psychanalyste\",\"\").str.replace(\"helléniste\",\"\").str.replace(\"professeur\",\"\")\\\n",
    "    .str.replace(\"consultant en écoconception\",\"\").str.replace(\"directrice artistique indépendante\",\"\").str.replace(\"en psychologie cognitive\",\"\").str.replace(\"diplômée en histoire\",\"\")\\\n",
    "    .str.replace(\"de cardiologue\",\"\").str.replace(\"professeure-formatrice\",\"\").str.replace(\"en traitement du signal\",\"\").str.replace(\"réflexologue\",\"\")\\\n",
    "    .str.replace(\"et  en archéologie\",\"\").str.replace(\"designer de logos\",\"\").str.replace(\"chercheur en psychologie cognitive\",\"\").str.replace(\"pour la jeunesse\",\"\")\\\n",
    "    .str.replace(\"philosophe\",\"\").str.replace(\"helléniste\",\"\").str.replace(\"en sciences et techniques des activités physiques et sportives\",\"\")\\\n",
    "    .str.replace('e-formatrice',\"\").str.replace(\"chercheur\",\"\").str.strip()\n",
    "\n",
    "# Fix 'authors' columns\n",
    "df_relevant_cols.loc[df_relevant_cols['authors'] == \"[]\", 'authors'] = \"<NA>\"\n",
    "df_relevant_cols.loc[df_relevant_cols['authors'] == \"['unknown author']\", 'authors'] = \"<NA>\"\n",
    "df_relevant_cols.loc[df_relevant_cols['authors'] == \"['No author stated']\", 'authors'] = \"<NA>\"\n",
    "df_relevant_cols['authors'] = df_relevant_cols['authors'].fillna(\"<NA>\")\n",
    "\n",
    "# Clean up the 'authors' column by removing specific phrases related to directors\n",
    "df_relevant_cols.loc[df_relevant_cols['authors'].str.contains(\"dir\"),'authors'] = (\n",
    "    df_relevant_cols.loc[df_relevant_cols['authors'].str.contains(\"dir\"),'authors']\\\n",
    "    .str.replace(\"(dir.)\",\"\").str.replace(\"(dir)\",\"\")\\\n",
    "        .str.replace(\"(sous la direction de)\",\"\").str.replace(\"(sous la direction)\",\"\")\\\n",
    "            .str.replace(\"Sous la direction de\",\"\").str.replace(\"()\",\"\")\n",
    ")\n",
    "\n",
    "# Clean up the 'authors' column by removing specific phrases related to authors\n",
    "df_relevant_cols.loc[df_relevant_cols['authors'].str.contains(\"author\"), 'authors'] = (\n",
    "    df_relevant_cols.loc[df_relevant_cols['authors'].str.contains(\"author\"), 'authors']\\\n",
    "    .str.replace(\"(author.)\", \"\").str.replace(\"(author)\", \"\")\n",
    ")\n",
    "\n",
    "# Remove commas from the 'Author' column\n",
    "df_relevant_cols['Author'] = df_relevant_cols['Author'].str.replace(\",\", \"\")\n",
    "df_relevant_cols.loc[df_relevant_cols['authors'] == \"<NA>\", 'authors'] = pd.NA\n",
    "\n",
    "# Combine the 'authors' and 'Author' columns, using backfill to fill missing values, then clean the resulting column\n",
    "df_relevant_cols[\"prep_author\"] = df_relevant_cols[['authors', 'Author']].fillna(method='bfill', axis=1).iloc[:, 0]\\\n",
    "    .str.replace(\"[\", '').str.replace(\"]\", '').str.replace(\"'\", '').str.replace(\"unknown author\", '<NA>')\\\n",
    "    .str.replace(\"<NA>\", '').fillna('')\n",
    "\n",
    "# If the 'authors' column contains numbers and the 'Author' column is not null, replace the 'prep_author' column with the value from the 'Author' column\n",
    "cond_fix_numbers_authors = df_relevant_cols['authors'].astype(str).str.contains(r\"[1|2|3|4|5|6|7|8|9|0]\")\n",
    "cond_notna_Author = ~df_relevant_cols['Author'].isna()\n",
    "df_relevant_cols.loc[\n",
    "    cond_fix_numbers_authors & cond_notna_Author, 'prep_author'\n",
    "] = df_relevant_cols.loc[\n",
    "    cond_fix_numbers_authors & cond_notna_Author, 'Author'\n",
    "]\n",
    "\n",
    "# Manually fix specific cases in the 'prep_author' column where incorrect formatting or data exists\n",
    "cond_manual_fix_1 = df_relevant_cols['prep_author'].astype(str).str.contains(r\"Camille Perrier, 1983, Joëlle Vuille\")\n",
    "cond_manual_fix_2 = df_relevant_cols['prep_author'].astype(str).str.contains(r\"Michel Hottelier, Maya Hertig, 1973, Alexandre Flückiger\")\n",
    "# Correct the 'prep_author' column for the identified cases\n",
    "df_relevant_cols.loc[cond_manual_fix_1, 'prep_author'] = \"Camille Perrier, Joëlle Vuille\"\n",
    "df_relevant_cols.loc[cond_manual_fix_2, 'prep_author'] = \"Michel Hottelier, Maya Hertig, Alexandre Flückiger\"\n",
    "\n",
    "df_relevant_cols[\"prep_synopsis\"] = df_relevant_cols['synopsis'].str.replace(\"<br/>\",\" \")\\\n",
    "    .str.replace(\"\\n\",\" \").str.replace(\"<br>\",\"\").fillna(\"<NA>\")\n",
    "\n",
    "df_relevant_cols[\"prep_publisher\"]  = df_relevant_cols[['publisher','Publisher']].fillna(method='bfill', axis=1).iloc[:, 0]\\\n",
    "    .fillna(\"<NA>\").str.replace(\"<NA>\",'')\n",
    "\n",
    "df_relevant_cols['Title'] =  df_relevant_cols['Title'].str.replace(\"/\",\"\").str.strip()\n",
    "df_relevant_cols[\"prep_title\"] = df_relevant_cols[['title_long','Title']].fillna(method='bfill', axis=1).iloc[:, 0]\\\n",
    "    .fillna('<NA>').str.replace(\"<NA>\",'')\n",
    "\n",
    "df_relevant_cols[\"prep_language\"] = df_relevant_cols['language'].fillna(\"<NA>\").str.replace(\"<NA>\",'')\n",
    "\n",
    "df_relevant_cols.loc[df_relevant_cols['subjects'] == \"['Subjects']\",'subjects'] = pd.NA\n",
    "df_relevant_cols['subjects'] = df_relevant_cols['subjects'].str.replace(\"[\",'').str.replace(\"]\",'').str.replace(\"'\",'')\n",
    "df_relevant_cols[\"prep_subjects\"] = df_relevant_cols[['subjects','Subjects']].fillna(method='bfill', axis=1).iloc[:, 0]\\\n",
    "    .fillna('<NA>').str.replace(\"<NA>\",'')\n",
    "\n",
    "df_relevant_cols['prep_pages'] = df_relevant_cols['pages'].astype('Int64').astype(str).str.replace(\"<NA>\",'')\n",
    "\n",
    "df_relevant_cols['prep_isbn'] = \"[\" + df_relevant_cols['ISBN Valid'].fillna(\"<NA>\").str.replace(\"<NA>\",'').str.replace(\";\",',') + \"]\"\n",
    "\n",
    "df_relevant_cols[\"prep_published\"] = df_relevant_cols['date_published'].fillna(\"<NA>\").str.replace(\"<NA>\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4e30ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess book data for TFIDF\n",
    "books['combined_features'] = (\n",
    "    df_relevant_cols['prep_title'].fillna('') + ' ' +\n",
    "    df_relevant_cols['prep_author'].fillna('') + ' ' +\n",
    "    df_relevant_cols['prep_isbn'].fillna('') + ' ' +\n",
    "    df_relevant_cols['prep_publisher'].fillna('') + ' ' +\n",
    "    # df_relevant_cols['prep_subjects'].fillna('') + ' ' +\n",
    "    # df_relevant_cols['prep_synopsis'].fillna('') + ' ' +\n",
    "    # df_relevant_cols['prep_language'].fillna('') + ' ' +\n",
    "    df_relevant_cols['prep_pages']\n",
    "    # df_relevant_cols['prep_published'].fillna('')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b58624b",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c2422a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer using French stop words and fit-transform the 'combined_features' column of the books\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=french_stop_words)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(books['combined_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd749cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m9/3cstgvvd2ds4y_qkq_p0lnrh0000gn/T/ipykernel_89410/3695254249.py:4: FutureWarning: The provided callable <built-in function min> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  interactions_agg = interactions.groupby('u').agg(\n",
      "/var/folders/m9/3cstgvvd2ds4y_qkq_p0lnrh0000gn/T/ipykernel_89410/3695254249.py:4: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  interactions_agg = interactions.groupby('u').agg(\n"
     ]
    }
   ],
   "source": [
    "# naive_limit_bool = True, if you want to limit the recommendations, otherwise set it to False\n",
    "naive_limit_bool = True\n",
    "\n",
    "interactions_agg = interactions.groupby('u').agg(\n",
    "    min_book_id = ('i', min),\n",
    "    max_book_id = ('i', max),\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# Compute recommendations for each user\n",
    "user_recommendations = {}\n",
    "for user_id, group in interactions.groupby('u'):\n",
    "    read_books = group['i'].values\n",
    "    read_books_indices = [books[books['i'] == book_id].index[0] for book_id in read_books]\n",
    "    read_books_tfidf = tfidf_matrix[read_books_indices]\n",
    "    similarity_scores = cosine_similarity(read_books_tfidf, tfidf_matrix)\n",
    "    avg_similarity = np.mean(similarity_scores, axis=0)\n",
    "    recommended_indices = avg_similarity.argsort()[-15288:][::-1]\n",
    "\n",
    "    recommended_books = books.iloc[recommended_indices]['i'].values\n",
    "\n",
    "    if naive_limit_bool:\n",
    "        lower_bound = interactions_agg[interactions_agg['u'] == user_id]['min_book_id'].values[0]\n",
    "        upper_bound = interactions_agg[interactions_agg['u'] == user_id]['max_book_id'].values[0]\n",
    "        \n",
    "        if upper_bound > lower_bound:\n",
    "            upper_bound = min(upper_bound+11, 15290)\n",
    "            recommended_books = recommended_books[(recommended_books >= lower_bound) & (recommended_books <= upper_bound)]\n",
    "\n",
    "        if len(recommended_books) < 10:\n",
    "            print(f\"User {user_id} has less than 10 recommendations. Found: {len(recommended_books)}\")\n",
    "            print(\"upper_bound:\", upper_bound)\n",
    "            print(\"lower_bound:\", lower_bound)\n",
    "    \n",
    "    user_recommendations[user_id] = recommended_books[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14d4d396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for User 0:\n",
      "[ 3 18 17 15 14 13 20  1 19  7]\n"
     ]
    }
   ],
   "source": [
    "# Display recommendations for a sample user\n",
    "sample_user_id = list(user_recommendations.keys())[0]\n",
    "print(f\"Recommendations for User {sample_user_id}:\")\n",
    "print(user_recommendations[sample_user_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations exported to recommendations_tfidf_naive_proper_input_less_features_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Export recommendations to a CSV file\n",
    "with open('recommendations_tfidf_naive_proper_input_less_features_cleaned.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['user_id', 'recommendation'])\n",
    "    for user_id, recommended_books in user_recommendations.items():\n",
    "        writer.writerow([user_id, \" \".join(map(str, recommended_books))])\n",
    "\n",
    "# Score = 0.1554\n",
    "print(\"Recommendations exported to recommendations_tfidf_naive_proper_input_less_features_cleaned.csv\")\n",
    "# Score = 0.1547\n",
    "print(\"Recommendations exported to recommendations_tfidf_proper_input_less_features_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73884f53",
   "metadata": {},
   "source": [
    "# Not successful attempts at all\n",
    "There were more different attempts, for the display purposes we left couple of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69944e30",
   "metadata": {},
   "source": [
    "### Generate BERT Embeddings Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcfcb8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# # Load the pre-trained model and tokenizer\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "# import torch\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "559353af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate embeddings for a given text\n",
    "# def generate_embeddings(text):\n",
    "#     if text is None or text == \"\" or pd.isna(text):\n",
    "#         return np.zeros((768,))\n",
    "#     inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "#     outputs = model(**inputs)\n",
    "#     embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "#     return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54354a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this function to the Title and Subjects columns\n",
    "# items['Title_Embeddings'] = items['Title'].apply(generate_embeddings)\n",
    "# items['Subjects_Embeddings'] = items['Subjects'].apply(generate_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef67035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the df with embeddings to a CSV file\n",
    "# items.to_csv('items_with_embeddings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c9bdf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# books_with_embeddings_df['Title_Embeddings'] = books_with_embeddings_df['Title_Embeddings'].apply(\n",
    "#     lambda x: np.array(x.replace('[','').replace(']','').replace('\\n', '').replace('  ', ' ').split(' '), dtype=float)\n",
    "# )\n",
    "\n",
    "# books_with_embeddings_df['Subjects_Embeddings'] = books_with_embeddings_df['Subjects_Embeddings'].apply(\n",
    "#     lambda x: np.array(x.replace('[','').replace(']','').replace('\\n', '').replace('  ', ' ').split(' '), dtype=float)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51aa93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the embeddings from the saved CSV file\n",
    "# books_with_embeddings_df = pd.read_csv('items_with_embeddings.csv')\n",
    "\n",
    "# books_with_embeddings_df['Title_Embeddings'] = books_with_embeddings_df['Title'].apply(generate_embeddings)\n",
    "# books_with_embeddings_df['Subjects_Embeddings'] = books_with_embeddings_df['Subjects'].apply(generate_embeddings)\n",
    "\n",
    "# # Combine the embeddings for a comprehensive representation\n",
    "# books_with_embeddings_df['Combined_Embeddings'] = books_with_embeddings_df.apply(\n",
    "#     lambda row: np.array(row['Title_Embeddings']) + np.array(row['Subjects_Embeddings']), axis=1\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffadd178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the combined embeddings to a matrix\n",
    "# embeddings_matrix = np.stack(books_with_embeddings_df['Combined_Embeddings'].values)\n",
    "\n",
    "# # Calculate cosine similarity between book embeddings\n",
    "# similarity_matrix = cosine_similarity(embeddings_matrix)\n",
    "\n",
    "# # Function to generate top-10 recommendations for each user\n",
    "# def generate_recommendations(user_interactions, similarity_matrix, top_k=10):\n",
    "#     recommendations = {}\n",
    "#     for user_id, interacted_books in user_interactions.items():\n",
    "#         # Calculate the mean similarity score for each book not interacted by the user\n",
    "#         scores = np.mean(similarity_matrix[interacted_books], axis=0)\n",
    "        \n",
    "#         # Exclude books the user has already interacted with\n",
    "#         scores[interacted_books] = -1\n",
    "        \n",
    "#         # Get the indices of the top-k books\n",
    "#         recommended_books = np.argsort(scores)[-top_k:][::-1]\n",
    "#         recommendations[user_id] = recommended_books\n",
    "#     return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b47f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # User interactions in the list format\n",
    "# user_interactions = interactions.groupby('u').agg(\n",
    "#     {'i': lambda x: list(x)}\n",
    "# ).to_dict()\n",
    "\n",
    "# user_interactions = user_interactions['i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "774f63ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# # Generate recommendations for all users\n",
    "# recommendations = generate_recommendations(user_interactions, similarity_matrix, top_k=10)\n",
    "\n",
    "# # Prepare submission format\n",
    "# submission_data = []\n",
    "# for user_id, recommended_books in recommendations.items():\n",
    "#     submission_data.append({'user_id': user_id, 'recommendation': ' '.join(map(str, recommended_books))})\n",
    "\n",
    "# # Create a DataFrame for submission\n",
    "# submission_df = pd.DataFrame(submission_data)\n",
    "\n",
    "# # Save to CSV\n",
    "# submission_df.to_csv('submission.csv', index=False)\n",
    "# print(\"Submission file created: submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a745d",
   "metadata": {},
   "source": [
    "### Collaborative Filtering with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc6bba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "1bd848f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = pd.read_csv('kaggle_data/interactions_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d22a57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates by taking the latest interaction timestamp for each user-item pair\n",
    "interactions_train_df = interactions_df.sort_values('t').drop_duplicates(subset=['u', 'i'], keep='last')\n",
    "\n",
    "# Prepare the interaction matrix\n",
    "interaction_matrix = interactions_train_df.pivot(index='u', columns='i', values='t').fillna(0)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(interactions_train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the training interaction matrix\n",
    "train_interaction_matrix = train_data.pivot(index='u', columns='i', values='t').fillna(0)\n",
    "\n",
    "# Create the test interaction matrix\n",
    "test_interaction_matrix = test_data.pivot(index='u', columns='i', values='t').fillna(0)\n",
    "\n",
    "# Ensure the matrices have the same columns\n",
    "train_interaction_matrix = train_interaction_matrix.reindex(columns=interaction_matrix.columns, fill_value=0)\n",
    "test_interaction_matrix = test_interaction_matrix.reindex(columns=interaction_matrix.columns, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "bb5000ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:960: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 947, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "TypeError: __call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ushakov/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=TruncatedSVD(),\n",
       "             param_grid={&#x27;n_components&#x27;: [10, 20, 50], &#x27;n_iter&#x27;: [10, 20, 30]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3, estimator=TruncatedSVD(),\n",
       "             param_grid={&#x27;n_components&#x27;: [10, 20, 50], &#x27;n_iter&#x27;: [10, 20, 30]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: TruncatedSVD</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>TruncatedSVD(n_components=10, n_iter=10)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TruncatedSVD</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.TruncatedSVD.html\">?<span>Documentation for TruncatedSVD</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TruncatedSVD(n_components=10, n_iter=10)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=TruncatedSVD(),\n",
       "             param_grid={'n_components': [10, 20, 50], 'n_iter': [10, 20, 30]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Selection and Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'n_components': [10, 20, 50],\n",
    "    'n_iter': [10, 20, 30]\n",
    "}\n",
    "\n",
    "svd = TruncatedSVD()\n",
    "grid_search = GridSearchCV(svd, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(train_interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e4383ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TruncatedSVD(n_components=10, n_iter=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TruncatedSVD</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.TruncatedSVD.html\">?<span>Documentation for TruncatedSVD</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>TruncatedSVD(n_components=10, n_iter=10)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TruncatedSVD(n_components=10, n_iter=10)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best model\n",
    "best_svd = grid_search.best_estimator_\n",
    "\n",
    "# Model Training\n",
    "best_svd.fit(train_interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4d4a344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get top N recommendations\n",
    "def get_top_n_recommendations(user_id, model, interaction_matrix, n=10):\n",
    "    \"\"\"\n",
    "    Generate top-N item recommendations for a given user.\n",
    "    \"\"\"\n",
    "    if user_id not in interaction_matrix.index:\n",
    "        return []\n",
    "    \n",
    "    user_interactions = interaction_matrix.loc[user_id].values.reshape(1, -1)\n",
    "    scores = model.transform(user_interactions).dot(model.components_)\n",
    "    top_n_items = np.argsort(scores[0])[::-1][:n]\n",
    "    return top_n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5695940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Precision@10\n",
    "def precision_at_k(test_matrix, train_matrix, model, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average Precision@K for all users in the test set.\n",
    "    \"\"\"\n",
    "    precisions = []\n",
    "\n",
    "    for user_id in test_matrix.index:\n",
    "        # Get the top-N recommendations\n",
    "        top_n = get_top_n_recommendations(user_id, model, train_matrix, n=k)\n",
    "        \n",
    "        # Get the actual items the user interacted with in the test set\n",
    "        actual_items = test_matrix.loc[user_id]\n",
    "        actual_items = actual_items[actual_items > 0].index.tolist()\n",
    "        \n",
    "        # Calculate the number of relevant items in top N\n",
    "        relevant_items = set(top_n).intersection(set(actual_items))\n",
    "        \n",
    "        # Precision is the number of relevant items found divided by N\n",
    "        precision = len(relevant_items) / k\n",
    "        precisions.append(precision)\n",
    "    \n",
    "    # Return the average Precision@K across all users\n",
    "    return np.mean(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4c4fe32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.0007\n"
     ]
    }
   ],
   "source": [
    "precision_10 = precision_at_k(test_interaction_matrix, train_interaction_matrix, best_svd, k=10)\n",
    "print(f\"Precision@10: {precision_10:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
