{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe38780",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cfdb375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010101ad",
   "metadata": {},
   "source": [
    "# Collaborative Filtering (first attempts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51384b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 65419\n",
      "Testing set size: 21628\n"
     ]
    }
   ],
   "source": [
    "interactions = pd.read_csv('kaggle_data/interactions_train.csv')\n",
    "items = pd.read_csv('kaggle_data/items.csv')\n",
    "\n",
    "interactions = interactions.sort_values([\"u\", \"t\"])\n",
    "interactions[\"pct_rank\"] = interactions.groupby(\"u\")[\"t\"].rank(pct=True, method='dense')\n",
    "interactions.reset_index(inplace=True, drop=True)\n",
    "\n",
    "train_interactions = interactions[interactions[\"pct_rank\"] < 0.8]\n",
    "test_interactions = interactions[interactions[\"pct_rank\"] >= 0.8]\n",
    "\n",
    "print(\"Training set size:\", train_interactions.shape[0])\n",
    "print(\"Testing set size:\", test_interactions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "844c0c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>i</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15279</th>\n",
       "      <th>15280</th>\n",
       "      <th>15282</th>\n",
       "      <th>15283</th>\n",
       "      <th>15284</th>\n",
       "      <th>15285</th>\n",
       "      <th>15287</th>\n",
       "      <th>15288</th>\n",
       "      <th>15289</th>\n",
       "      <th>15290</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7838 rows × 14589 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "i     0      1      2      3      4      5      6      7      8      9      \\\n",
       "u                                                                            \n",
       "0         1      1      1      1      1      1      1      1      1      1   \n",
       "1         0      0      0      0      0      0      0      0      0      0   \n",
       "2         0      0      0      0      0      0      0      0      0      0   \n",
       "3         0      0      0      0      0      0      0      0      0      0   \n",
       "4         0      0      0      0      0      0      0      0      0      0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "7833      0      0      0      0      0      0      0      0      0      0   \n",
       "7834      0      0      0      0      0      0      0      0      0      0   \n",
       "7835      0      0      0      0      0      0      0      0      0      0   \n",
       "7836      0      0      0      0      0      0      0      0      0      0   \n",
       "7837      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "i     ...  15279  15280  15282  15283  15284  15285  15287  15288  15289  \\\n",
       "u     ...                                                                  \n",
       "0     ...      0      0      0      0      0      0      0      0      0   \n",
       "1     ...      0      0      0      0      0      0      0      0      0   \n",
       "2     ...      0      0      0      0      0      0      0      0      0   \n",
       "3     ...      0      0      0      0      0      0      0      0      0   \n",
       "4     ...      0      0      0      0      0      0      0      0      0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "7833  ...      0      0      0      0      0      0      0      0      0   \n",
       "7834  ...      0      0      0      0      0      0      0      0      0   \n",
       "7835  ...      0      0      0      0      0      0      0      0      0   \n",
       "7836  ...      0      0      0      0      0      0      0      0      0   \n",
       "7837  ...      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "i     15290  \n",
       "u            \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "7833      0  \n",
       "7834      0  \n",
       "7835      0  \n",
       "7836      0  \n",
       "7837      0  \n",
       "\n",
       "[7838 rows x 14589 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a user-item interaction matrix with binary values (1 if read, 0 otherwise)\n",
    "binary_interaction_matrix = train_interactions.pivot_table(index='u', columns='i', values='t', aggfunc='count')\n",
    "binary_interaction_matrix = binary_interaction_matrix.notnull().astype(int)\n",
    "\n",
    "binary_interaction_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c513d",
   "metadata": {},
   "source": [
    "## User To User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b61410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>u</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7828</th>\n",
       "      <th>7829</th>\n",
       "      <th>7830</th>\n",
       "      <th>7831</th>\n",
       "      <th>7832</th>\n",
       "      <th>7833</th>\n",
       "      <th>7834</th>\n",
       "      <th>7835</th>\n",
       "      <th>7836</th>\n",
       "      <th>7837</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7833</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7835</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7836</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7838 rows × 7838 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "u     0     1     2     3     4     5     6     7     8     9     ...  7828  \\\n",
       "u                                                                 ...         \n",
       "0      1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1      0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2      0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3      0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4      0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "7833   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "7834   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "7835   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "7836   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "7837   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "u     7829  7830  7831  7832  7833  7834  7835  7836  7837  \n",
       "u                                                           \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "7833   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0  \n",
       "7834   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0  \n",
       "7835   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  \n",
       "7836   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0  \n",
       "7837   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n",
       "\n",
       "[7838 rows x 7838 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similarity between users\n",
    "\n",
    "user_similarity = cosine_similarity(binary_interaction_matrix)\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=binary_interaction_matrix.index, columns=binary_interaction_matrix.index)\n",
    "user_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ce6e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8     9\n",
      "u                                                   \n",
      "0   13    4   12   15   14   11    8   10    9     5\n",
      "1   34   30   29   37   31   32   33   36   35  1573\n",
      "2   46   58   53   49   56   82   64   75   45    67\n",
      "3  149   40  138  155  128  142  143  156  133   139\n",
      "4  202  198  191  203  193  201  197  196  199   195\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "# 1. user-item scores for every user in one shot\n",
    "scores = user_similarity_df.values @ binary_interaction_matrix.values        # (U, I)\n",
    "\n",
    "# 2. indices of each user’s k best-scoring items (unsorted)\n",
    "top_idx_unsorted = np.argpartition(-scores, k-1, axis=1)[:, :k]              # (U, k)\n",
    "\n",
    "# 3. sort those k items per user so they’re really rank-ordered\n",
    "rows   = np.arange(scores.shape[0])[:, None]                                  # (U, 1)\n",
    "order  = np.argsort(-scores[rows, top_idx_unsorted], axis=1)\n",
    "top_idx = top_idx_unsorted[rows, order]                                       # (U, k) sorted\n",
    "\n",
    "# 4. look up the *labels* with NumPy → 2-D array → DataFrame\n",
    "item_labels = binary_interaction_matrix.columns.to_numpy()                    # (I,)\n",
    "top_labels  = item_labels[top_idx]                                            # (U, k)\n",
    "\n",
    "recommendations = pd.DataFrame(\n",
    "    top_labels,                              # the items\n",
    "    index=binary_interaction_matrix.index,   # the users\n",
    "    columns=range(k)                         # rank 0…9\n",
    ")\n",
    "\n",
    "# quick peek\n",
    "print(recommendations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad256a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_precision_recall(recommendations, test_interactions, k=10):\n",
    "    # Create a mapping from user to the set of items they interacted with in the test set\n",
    "    test_user_items = test_interactions.groupby('u')['i'].apply(set)\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    # Calculate precision and recall for each user with test interactions\n",
    "    for user, rec_items in recommendations.iterrows():\n",
    "        if user in test_user_items:\n",
    "            relevant_items = test_user_items[user]\n",
    "            rec_set = set(rec_items.values)\n",
    "            true_positives = len(rec_set.intersection(relevant_items))\n",
    "            precision = true_positives / len(rec_set)\n",
    "            recall = true_positives / len(relevant_items) if len(relevant_items) > 0 else 0\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            \n",
    "    # Compute average precision and recall over all evaluated users\n",
    "    avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
    "    avg_recall = sum(recalls) / len(recalls) if recalls else 0\n",
    "    \n",
    "    print(\"Average Precision at {}: {}\".format(k, avg_precision))\n",
    "    print(\"Average Recall at {}: {}\".format(k, avg_recall))\n",
    "    \n",
    "    return avg_precision, avg_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d2a60a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision at 10: 0.05646848685889258\n",
      "Average Recall at 10: 0.290439819786585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05646848685889258, 0.290439819786585)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_precision_recall(recommendations, test_interactions, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ec883",
   "metadata": {},
   "source": [
    "## Item to Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065b8a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>i</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15279</th>\n",
       "      <th>15280</th>\n",
       "      <th>15282</th>\n",
       "      <th>15283</th>\n",
       "      <th>15284</th>\n",
       "      <th>15285</th>\n",
       "      <th>15287</th>\n",
       "      <th>15288</th>\n",
       "      <th>15289</th>\n",
       "      <th>15290</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094491</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.109109</td>\n",
       "      <td>0.094491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077152</td>\n",
       "      <td>0.094491</td>\n",
       "      <td>0.094491</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15285</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15287</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15288</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15289</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15290</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14589 rows × 14589 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "i         0         1         2         3         4         5         6      \\\n",
       "i                                                                             \n",
       "0      1.000000  0.408248  0.333333  0.288675  0.109109  0.235702  0.288675   \n",
       "1      0.408248  1.000000  0.408248  0.353553  0.133631  0.288675  0.353553   \n",
       "2      0.333333  0.408248  1.000000  0.288675  0.109109  0.235702  0.288675   \n",
       "3      0.288675  0.353553  0.288675  1.000000  0.094491  0.204124  0.250000   \n",
       "4      0.109109  0.133631  0.109109  0.094491  1.000000  0.077152  0.094491   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15285  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15287  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15288  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15289  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15290  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "i         7         8         9      ...  15279  15280  15282  15283  15284  \\\n",
       "i                                    ...                                      \n",
       "0      0.288675  0.218218  0.218218  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "1      0.353553  0.267261  0.267261  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "2      0.288675  0.218218  0.218218  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "3      0.250000  0.188982  0.188982  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "4      0.094491  0.071429  0.142857  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "...         ...       ...       ...  ...    ...    ...    ...    ...    ...   \n",
       "15285  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "15287  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "15288  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "15289  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "15290  0.000000  0.000000  0.000000  ...    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "i      15285  15287  15288  15289  15290  \n",
       "i                                         \n",
       "0        0.0    0.0    0.0    0.0    0.0  \n",
       "1        0.0    0.0    0.0    0.0    0.0  \n",
       "2        0.0    0.0    0.0    0.0    0.0  \n",
       "3        0.0    0.0    0.0    0.0    0.0  \n",
       "4        0.0    0.0    0.0    0.0    0.0  \n",
       "...      ...    ...    ...    ...    ...  \n",
       "15285    1.0    0.0    0.0    0.0    0.0  \n",
       "15287    0.0    1.0    0.0    0.0    0.0  \n",
       "15288    0.0    0.0    1.0    0.0    0.0  \n",
       "15289    0.0    0.0    0.0    1.0    0.0  \n",
       "15290    0.0    0.0    0.0    0.0    1.0  \n",
       "\n",
       "[14589 rows x 14589 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity = cosine_similarity(binary_interaction_matrix.T)\n",
    "item_similarity_df = pd.DataFrame(item_similarity, index=binary_interaction_matrix.columns, columns=binary_interaction_matrix.columns)\n",
    "item_similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca43a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4    5    6    7    8     9\n",
      "u                                                   \n",
      "0   18   11   14   15    1   12    0    2    6     3\n",
      "1   33   36   31   35   32   29   30   37   34  2988\n",
      "2   80   76   84   54   86   73   60   77   47    50\n",
      "3  123  132  157  134  130  150  151  124  152   117\n",
      "4  192  200  204  194  195  196  199  203  197   191\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "# 1. compute user-item scores using item similarity\n",
    "# binary_interaction_matrix: (U, I)\n",
    "# item_similarity_df: (I, I)\n",
    "scores = binary_interaction_matrix.values @ item_similarity_df.values  # (U, I)\n",
    "\n",
    "# 2. indices of each user's k best-scoring items (unsorted)\n",
    "top_idx_unsorted = np.argpartition(-scores, k-1, axis=1)[:, :k]         # (U, k)\n",
    "\n",
    "# 3. sort those k items per user to get rank-ordered recommendations\n",
    "rows = np.arange(scores.shape[0])[:, None]                              # (U, 1)\n",
    "order = np.argsort(-scores[rows, top_idx_unsorted], axis=1)\n",
    "top_idx = top_idx_unsorted[rows, order]                                   # (U, k) sorted\n",
    "\n",
    "# 4. look up the item labels (assuming column labels represent item ids)\n",
    "item_labels = binary_interaction_matrix.columns.to_numpy()               # (I,)\n",
    "top_labels = item_labels[top_idx]                                        # (U, k)\n",
    "\n",
    "recommendations = pd.DataFrame(\n",
    "    top_labels,                              # recommended items\n",
    "    index=binary_interaction_matrix.index,   # users\n",
    "    columns=range(k)                         # ranks 0…9\n",
    ")\n",
    "\n",
    "print(recommendations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "171eff52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision at 10: 0.05931360040826742\n",
      "Average Recall at 10: 0.2816780249109841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05931360040826742, 0.2816780249109841)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_precision_recall(recommendations, test_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8dcb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each row of recommendations to a space-separated string\n",
    "recommendations_str = recommendations.apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
    "\n",
    "# Export to CSV with a single-column header\n",
    "recommendations_str.to_csv('recommendation_CF_item_item.csv', index=True, header=['recommendation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f011c",
   "metadata": {},
   "source": [
    "# Collaborative Filtering (the best scores)\n",
    "Recommendations based on user-item interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "093bf7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable or disable the upscaling of individual book weights for users with low book counts\n",
    "upscale_low_book = True\n",
    "\n",
    "# Define the threshold for the number of books below which upscaling will be applied\n",
    "threshold_low_book = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c94883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 65419\n",
      "Testing set size: 21628\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "interactions = pd.read_csv('kaggle_data/interactions_train.csv')\n",
    "items = pd.read_csv('kaggle_data/items.csv')\n",
    "\n",
    "interactions = interactions.sort_values([\"u\", \"t\"])\n",
    "interactions[\"pct_rank\"] = interactions.groupby(\"u\")[\"t\"].rank(pct=True, method='dense')\n",
    "interactions.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_interactions = interactions[interactions[\"pct_rank\"] < 0.8]\n",
    "test_interactions = interactions[interactions[\"pct_rank\"] >= 0.8]\n",
    "\n",
    "print(\"Training set size:\", train_interactions.shape[0])\n",
    "print(\"Testing set size:\", test_interactions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887e0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate train_interactions to calculate the number of unique items each user has interacted with\n",
    "train_interactions_agg = train_interactions.groupby('u').agg(\n",
    "    {\n",
    "        'i': pd.Series.nunique,\n",
    "    }\n",
    ").reset_index().rename(\n",
    "    columns={\n",
    "        'i': 'n_items'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Check the loaded data\n",
    "# Ensure the train_interactions dataset contains the required columns and is not empty\n",
    "assert 'u' in train_interactions.columns and 'i' in train_interactions.columns and 't' in train_interactions.columns, \"train_interactions file missing required columns\"\n",
    "assert not train_interactions.empty, \"train_interactions dataset is empty\"\n",
    "\n",
    "# Ensure the items dataset contains the required columns and is not empty\n",
    "assert 'Title' in items.columns and 'i' in items.columns, \"Items file missing required columns\"\n",
    "assert not items.empty, \"Items dataset is empty\"\n",
    "\n",
    "# Following adjustments\n",
    "train_interactions = train_interactions.sort_values([\"u\", \"t\"], ascending=[True, False])\n",
    "\n",
    "# Calculate the percentile rank of each interaction within a user's train_interactions\n",
    "train_interactions[\"pct_rank\"] = train_interactions.groupby(\"u\")[\"t\"].rank(pct=True, method='dense')\n",
    "train_interactions.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Merge the train_interactions dataset with the aggregated data to include the number of unique items per user\n",
    "train_interactions = train_interactions.merge(train_interactions_agg, on='u', how='left')\n",
    "train_interactions['weight'] = train_interactions[\"pct_rank\"]\n",
    "\n",
    "# If the upscale_low_book flag is True, assign a weight of 1 to train_interactions for users with a number of unique items less than or equal to the threshold\n",
    "if upscale_low_book:\n",
    "    train_interactions.loc[train_interactions['n_items'] <= threshold_low_book, 'weight'] = 1\n",
    "\n",
    "inter_data = train_interactions.copy()\n",
    "\n",
    "# Create binary interaction matrix\n",
    "binary_interaction_matrix = inter_data.pivot_table(index='u', columns='i', values='weight', aggfunc='sum')\n",
    "binary_interaction_matrix = binary_interaction_matrix.fillna(0)  # Fill NaN with 0\n",
    "\n",
    "# Compute cosine similarity and test symmetry\n",
    "user_similarity = cosine_similarity(binary_interaction_matrix)\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=binary_interaction_matrix.index, columns=binary_interaction_matrix.index)\n",
    "\n",
    "assert np.allclose(user_similarity_df, user_similarity_df.T), \"User similarity matrix is not symmetric\"\n",
    "\n",
    "# Top-10 Recommendations from this approach\n",
    "k = 10\n",
    "scores = user_similarity_df.values @ binary_interaction_matrix.values\n",
    "top_idx_unsorted = np.argpartition(-scores, k-1, axis=1)[:, :k]              \n",
    "rows = np.arange(scores.shape[0])[:, None]\n",
    "order = np.argsort(-scores[rows, top_idx_unsorted], axis=1)\n",
    "top_idx = top_idx_unsorted[rows, order]\n",
    "item_labels = binary_interaction_matrix.columns.to_numpy()                    \n",
    "top_labels = item_labels[top_idx]                                            \n",
    "recommendations = pd.DataFrame(top_labels, index=binary_interaction_matrix.index, columns=range(k))\n",
    "assert recommendations.shape[0] == binary_interaction_matrix.shape[0], \"Number of recommendation rows differs from number of users\"\n",
    "assert recommendations.shape[1] == k, \"Each user should have 10 recommendations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f2abc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision at 10: 0.06033426894615974\n",
      "Average Recall at 10: 0.28928699997495383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06033426894615974, 0.28928699997495383)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_precision_recall(recommendations, test_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca3806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit on full dataset\n",
    "# interactions agg to get unique books\n",
    "interactions_agg = interactions.groupby('u').agg(\n",
    "    {\n",
    "        'i': pd.Series.nunique,\n",
    "    }\n",
    ").reset_index().rename(\n",
    "    columns={\n",
    "        'i': 'n_items'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Check the loaded data\n",
    "# Ensure the train_interactions dataset contains the required columns and is not empty\n",
    "assert 'u' in interactions.columns and 'i' in interactions.columns and 't' in interactions.columns, \"Interactions file missing required columns\"\n",
    "assert not interactions.empty, \"Interactions dataset is empty\"\n",
    "\n",
    "# Ensure the items dataset contains the required columns and is not empty\n",
    "assert 'Title' in items.columns and 'i' in items.columns, \"Items file missing required columns\"\n",
    "assert not items.empty, \"Items dataset is empty\"\n",
    "\n",
    "# Merge the train_interactions dataset with the aggregated data to include the number of unique items per user\n",
    "interactions = interactions.sort_values([\"u\", \"t\"], ascending=[True, False])\n",
    "interactions[\"pct_rank\"] = interactions.groupby(\"u\")[\"t\"].rank(pct=True, method='dense')\n",
    "interactions.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "interactions = interactions.merge(interactions_agg, on='u', how='left')\n",
    "interactions['weight'] = interactions[\"pct_rank\"]\n",
    "\n",
    "# If the upscale_low_book flag is True, assign a weight of 1 to train_interactions for users with a number of unique items less than or equal to the threshold\n",
    "if upscale_low_book:\n",
    "    interactions.loc[interactions['n_items'] <= threshold_low_book, 'weight'] = 1\n",
    "train_data = interactions.copy()\n",
    "\n",
    "# Create binary interaction matrix\n",
    "binary_interaction_matrix = train_data.pivot_table(index='u', columns='i', values='weight', aggfunc='sum')\n",
    "binary_interaction_matrix = binary_interaction_matrix.fillna(0)  # Fill NaN with 0\n",
    "\n",
    "# Compute cosine similarity and test symmetry\n",
    "user_similarity = cosine_similarity(binary_interaction_matrix)\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=binary_interaction_matrix.index, columns=binary_interaction_matrix.index)\n",
    "# The similarity matrix should be symmetric\n",
    "assert np.allclose(user_similarity_df, user_similarity_df.T), \"User similarity matrix is not symmetric\"\n",
    "\n",
    "# Top-10 Recommendations from this approach\n",
    "k = 10\n",
    "scores = user_similarity_df.values @ binary_interaction_matrix.values\n",
    "top_idx_unsorted = np.argpartition(-scores, k-1, axis=1)[:, :k]\n",
    "rows = np.arange(scores.shape[0])[:, None]\n",
    "order = np.argsort(-scores[rows, top_idx_unsorted], axis=1)\n",
    "top_idx = top_idx_unsorted[rows, order]\n",
    "item_labels = binary_interaction_matrix.columns.to_numpy()                    \n",
    "top_labels = item_labels[top_idx]                                            \n",
    "recommendations = pd.DataFrame(top_labels, index=binary_interaction_matrix.index, columns=range(k))\n",
    "assert recommendations.shape[0] == binary_interaction_matrix.shape[0], \"Number of recommendation rows differs from number of users\"\n",
    "assert recommendations.shape[1] == k, \"Each user should have 10 recommendations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b2a8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each row of recommendations to a space-separated string\n",
    "recommendations_str = recommendations.apply(lambda row: ' '.join(row.astype(str)), axis=1)\n",
    "\n",
    "# Export recommendations to a CSV file\n",
    "if upscale_low_book:\n",
    "    recommendations_str.to_csv(\n",
    "        f'recommendations_collab_weight_pct_upscale_1_nitems_{threshold_low_book}.csv',\n",
    "        index=True,\n",
    "        header=['recommendation'],\n",
    "        index_label='user_id'\n",
    "    )\n",
    "else:\n",
    "    recommendations_str.to_csv(\n",
    "        'recommendations_collab_weight_pct.csv',\n",
    "        index=True,\n",
    "        header=['recommendation'],\n",
    "        index_label='user_id'\n",
    "    )\n",
    "\n",
    "# recommendations_collab_weight_pct_upscale_1_nitems_2.csv = 0.1642 (the best score)\n",
    "# recommendations_collab_weight_pct.csv = 0.1637 (the second best score): without upscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9e987e",
   "metadata": {},
   "source": [
    "# TFIDF-Based Book Recommendations (not cleaned dataset)\n",
    "This section demonstrates how to generate book recommendations for each user based on the similarity of books they have already read using the TFIDF approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34c0a539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/leonardogreco/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load book complete data\n",
    "books = pd.read_csv('kaggle_data/books_complete.csv')\n",
    "\n",
    "# Download the NLTK stopwords dataset\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the list of French stop words from the NLTK stopwords corpus\n",
    "french_stop_words = stopwords.words('french')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc070eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better embeddings + better input data\n",
    "# Drop unnecessary columns from the books dataframe\n",
    "df_relevant_cols = books.drop(\n",
    "    columns = [\"dewey_decimal\",\"image\",'image_original','dimensions_structured',\n",
    "               'msrp','binding','edition','related','dimensions',]\n",
    ")\n",
    "\n",
    "# Combine 'authors' and 'Author' columns, clean up the data\n",
    "df_relevant_cols[\"prep_author\"] = df_relevant_cols[['authors','Author']].fillna(method='bfill', axis=1).iloc[:, 0]\\\n",
    "    .str.replace(\"[\",'').str.replace(\"]\",'').str.replace(\"'\",'').str.replace(\"unknown author\",'')\n",
    "\n",
    "# Clean up the 'synopsis' column\n",
    "df_relevant_cols[\"prep_synopsis\"] = df_relevant_cols['synopsis'].str.replace(\"<br/>\",\" \")\\\n",
    "    .str.replace(\"\\n\",\" \").str.replace(\"<br>\",\"\")\n",
    "\n",
    "# Combine 'publisher' and 'Publisher' columns, clean up the data\n",
    "df_relevant_cols[\"prep_publisher\"] = df_relevant_cols[['publisher','Publisher']].fillna(method='bfill', axis=1).iloc[:, 0]\n",
    "\n",
    "# Combine 'title_long' and 'Title' columns, clean up the data\n",
    "df_relevant_cols[\"prep_title\"] = df_relevant_cols[['title_long','Title']].fillna(method='bfill', axis=1).iloc[:, 0]\n",
    "\n",
    "# Copy the 'language' column to 'prep_language'\n",
    "df_relevant_cols[\"prep_language\"] = df_relevant_cols['language']\n",
    "\n",
    "# Clean up the 'subjects' column and store in 'prep_subjects'\n",
    "df_relevant_cols.loc[df_relevant_cols['subjects'] == \"['Subjects']\",'subjects'] = pd.NA\n",
    "df_relevant_cols['subjects'] = df_relevant_cols['subjects'].str.replace(\"[\",'').str.replace(\"]\",'').str.replace(\"'\",'')\n",
    "df_relevant_cols[\"prep_subjects\"] = df_relevant_cols[['subjects','Subjects']].fillna(method='bfill', axis=1).iloc[:, 0]\n",
    "\n",
    "# Convert 'pages' column to string\n",
    "df_relevant_cols['prep_pages'] = df_relevant_cols['pages'].astype('Int64').astype(str)\n",
    "\n",
    "# Copy the 'ISBN Valid' column to 'prep_isbn'\n",
    "df_relevant_cols['prep_isbn'] = df_relevant_cols['ISBN Valid']\n",
    "\n",
    "# Copy the 'date_published' column to 'prep_published'\n",
    "df_relevant_cols[\"prep_published\"] = df_relevant_cols['date_published']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c5b6bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess book data for TFIDF\n",
    "books['combined_features'] = (\n",
    "    df_relevant_cols['prep_title'].fillna('') + ' ' +\n",
    "    df_relevant_cols['prep_author'].fillna('') + ' ' +\n",
    "    df_relevant_cols['prep_isbn'].fillna('') + ' ' +\n",
    "    df_relevant_cols['prep_publisher'].fillna('') + ' ' +\n",
    "    # df_relevant_cols['prep_subjects'].fillna('') + ' ' +\n",
    "    # df_relevant_cols['prep_synopsis'].fillna('') + ' ' + other features lead to a lower score\n",
    "    # df_relevant_cols['prep_language'].fillna('') + ' ' +\n",
    "    df_relevant_cols['prep_pages'].str.replace(\"<NA>\",\"\")\n",
    "    # df_relevant_cols['prep_published'].fillna('')\n",
    ")\n",
    "\n",
    "books['combined_features'] = books['combined_features'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e212696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interactions = interactions[interactions[\"pct_rank\"] < 0.8]\n",
    "test_interactions = interactions[interactions[\"pct_rank\"] >= 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b201ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a TF-IDF vectorizer using French stop words and fit-transform the 'combined_features' column of the books\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=french_stop_words)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(books['combined_features'].fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a591fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive_limit_bool = True, if you want to limit the recommendations, otherwise set it to False\n",
    "naive_limit_bool = True\n",
    "\n",
    "interactions_agg = train_interactions.groupby('u').agg(\n",
    "    min_book_id = ('i', min),\n",
    "    max_book_id = ('i', max),\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# Compute recommendations for each user\n",
    "user_recommendations = {}\n",
    "for user_id, group in interactions.groupby('u'):\n",
    "    read_books = group['i'].values\n",
    "    read_books_indices = [books[books['i'] == book_id].index[0] for book_id in read_books]\n",
    "    read_books_tfidf = tfidf_matrix[read_books_indices]\n",
    "    similarity_scores = cosine_similarity(read_books_tfidf, tfidf_matrix)\n",
    "    avg_similarity = np.mean(similarity_scores, axis=0)\n",
    "    recommended_indices = avg_similarity.argsort()[-15288:][::-1]\n",
    "\n",
    "    recommended_books = books.iloc[recommended_indices]['i'].values\n",
    "\n",
    "    if naive_limit_bool:\n",
    "        lower_bound = interactions_agg[interactions_agg['u'] == user_id]['min_book_id'].values[0]\n",
    "        upper_bound = interactions_agg[interactions_agg['u'] == user_id]['max_book_id'].values[0]\n",
    "        \n",
    "        if upper_bound > lower_bound:\n",
    "            upper_bound = min(upper_bound+11, 15290)\n",
    "            recommended_books = recommended_books[(recommended_books >= lower_bound) & (recommended_books <= upper_bound)]\n",
    "\n",
    "        if len(recommended_books) < 10:\n",
    "            print(f\"User {user_id} has less than 10 recommendations. Found: {len(recommended_books)}\")\n",
    "            print(\"upper_bound:\", upper_bound)\n",
    "            print(\"lower_bound:\", lower_bound)\n",
    "    \n",
    "    user_recommendations[user_id] = recommended_books[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98343878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision at 10: 0.13916815514161776\n",
      "Average Recall at 10: 0.6400121269555963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13916815514161776, 0.6400121269555963)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_precision_recall(pd.DataFrame(user_recommendations).T, test_interactions, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0491e709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for User 0:\n",
      "[ 3 18 17 15 14 13 20 19  7  6]\n"
     ]
    }
   ],
   "source": [
    "# Display recommendations for a sample user\n",
    "sample_user_id = list(user_recommendations.keys())[0]\n",
    "print(f\"Recommendations for User {sample_user_id}:\")\n",
    "print(user_recommendations[sample_user_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d747103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations exported to recommendations_tfidf_naive_proper_input_less_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Export recommendations to a CSV file\n",
    "with open('recommendations_tfidf_naive_proper_input_less_features.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['user_id', 'recommendation'])\n",
    "    for user_id, recommended_books in user_recommendations.items():\n",
    "        writer.writerow([user_id, \" \".join(map(str, recommended_books))])\n",
    "\n",
    "# Score = 0.1560\n",
    "print(\"Recommendations exported to recommendations_tfidf_naive_proper_input_less_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5450ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "      <th>t</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>last_unique_books</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>36</td>\n",
       "      <td>669</td>\n",
       "      <td>1.717176e+09</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>76</td>\n",
       "      <td>1345</td>\n",
       "      <td>1.685960e+09</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>178</td>\n",
       "      <td>2406</td>\n",
       "      <td>1.694169e+09</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>188</td>\n",
       "      <td>2577</td>\n",
       "      <td>1.701194e+09</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>218</td>\n",
       "      <td>611</td>\n",
       "      <td>1.689785e+09</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65295</th>\n",
       "      <td>7810</td>\n",
       "      <td>4426</td>\n",
       "      <td>1.726226e+09</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65314</th>\n",
       "      <td>7816</td>\n",
       "      <td>14826</td>\n",
       "      <td>1.727356e+09</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65320</th>\n",
       "      <td>7818</td>\n",
       "      <td>14555</td>\n",
       "      <td>1.726739e+09</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65354</th>\n",
       "      <td>7823</td>\n",
       "      <td>53</td>\n",
       "      <td>1.726938e+09</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65400</th>\n",
       "      <td>7832</td>\n",
       "      <td>15290</td>\n",
       "      <td>1.727884e+09</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>587 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          u      i             t  pct_rank  last_unique_books\n",
       "636      36    669  1.717176e+09  0.750000                  1\n",
       "1244     76   1345  1.685960e+09  0.666667                  1\n",
       "2322    178   2406  1.694169e+09  0.785714                  1\n",
       "2472    188   2577  1.701194e+09  0.600000                  1\n",
       "2767    218    611  1.689785e+09  0.666667                  1\n",
       "...     ...    ...           ...       ...                ...\n",
       "65295  7810   4426  1.726226e+09  0.727273                  1\n",
       "65314  7816  14826  1.727356e+09  0.666667                  1\n",
       "65320  7818  14555  1.726739e+09  0.714286                  1\n",
       "65354  7823     53  1.726938e+09  0.761905                  1\n",
       "65400  7832  15290  1.727884e+09  0.714286                  1\n",
       "\n",
       "[587 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each user, who has read only one unique book (does not matter once or several times), recommend 10 times the same book\n",
    "user_embeddings_df = train_interactions.copy()\n",
    "\n",
    "user_embeddings_df = user_embeddings_df.sort_values(by=[\"u\", \"t\"],ascending=[True, False]).reset_index(drop=True)\n",
    "user_embeddings_df['last_unique_books'] = user_embeddings_df\\\n",
    "        .groupby('u')['i']\\\n",
    "        .apply(lambda x: (~pd.Series(x).duplicated()).cumsum()).reset_index(drop=True)\n",
    "\n",
    "# Get users who have read exactly 1 unique book\n",
    "users_with_1_unique_book = user_embeddings_df.groupby('u')['i'].nunique()\n",
    "users_with_1_unique_book = users_with_1_unique_book[users_with_1_unique_book == 1].index\n",
    "u_1 = user_embeddings_df[user_embeddings_df['u'].isin(users_with_1_unique_book)].drop_duplicates(subset=['u', 'i'])\n",
    "u_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9311701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id in u_1['u'].unique():\n",
    "    book_id = u_1[u_1['u'] == user_id]['i'].values[0]\n",
    "    # Create a recommendation list with 10 copies of the book ID\n",
    "    user_recommendations[user_id] = [book_id] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2807d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations exported to recommendations_tfidf_naive_proper_input_less_features_1.csv\n"
     ]
    }
   ],
   "source": [
    "# Export recommendations to a CSV file\n",
    "with open('recommendations_tfidf_naive_proper_input_less_features_1.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['user_id', 'recommendation'])\n",
    "    for user_id, recommended_books in user_recommendations.items():\n",
    "        writer.writerow([user_id, \" \".join(map(str, recommended_books))])\n",
    "\n",
    "# Score = 0.1558\n",
    "print(\"Recommendations exported to recommendations_tfidf_naive_proper_input_less_features_1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
